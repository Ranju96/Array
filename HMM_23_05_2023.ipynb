{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvMSTJSHg28W+PFTpVtHp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranju96/Array/blob/main/HMM_23_05_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##TOPIC: Demonstration of HMM based Isolated word recognition from Speech\n",
        "\n"
      ],
      "metadata": {
        "id": "VEVAKYlPUxvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05WcuOegM2qP",
        "outputId": "57f57f88-748a-444d-f1f6-77d9bbddd6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Source : https://www.voiptroubleshooter.com/open_speech/american.html"
      ],
      "metadata": {
        "id": "2JNKG-TIUKhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import  library"
      ],
      "metadata": {
        "id": "4AJJjaBvTvJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeHW690VMuQP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the words to be recognized"
      ],
      "metadata": {
        "id": "QabNSjvLTqW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the words to be recognized\n",
        "words = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "\n",
        "# Load the speech WAV file\n",
        "sample_rate, signal = wavfile.read('/content/OSR_us_000_0039_8k.wav')"
      ],
      "metadata": {
        "id": "DBWeYCsfRUjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess "
      ],
      "metadata": {
        "id": "ZsZGvv4sTjQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Preprocess the signal\n",
        "signal = signal.astype(float)\n",
        "signal /= np.max(np.abs(signal))"
      ],
      "metadata": {
        "id": "yNyPpbwCS0TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the HMM models for each word\n",
        "models = []\n",
        "for word in words:\n",
        "    model = hmm.GaussianHMM(n_components=3, covariance_type=\"diag\")\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "zrheGyn5xkuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the HMM models\n",
        "for i, model in enumerate(models):\n",
        "    samples = signal[int(i * len(signal) / len(words)):int((i + 1) * len(signal) / len(words))]\n",
        "    lengths = [len(samples)]\n",
        "    model.fit(samples.reshape(-1, 1), lengths)"
      ],
      "metadata": {
        "id": "ft9c7zJlxoh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recognize the word from the test signal"
      ],
      "metadata": {
        "id": "yh8Az986U7GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recognize the word from the test signal\n",
        "test_word = signal[:int(len(signal) / len(words))]\n",
        "test_lengths = [len(test_word)]\n",
        "scores = []\n",
        "for model in models:\n",
        "    score = model.score(test_word.reshape(-1, 1), test_lengths)\n",
        "    scores.append(score)\n"
      ],
      "metadata": {
        "id": "j3ulUjjhSr5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the recognized word\n",
        "recognized_word = words[np.argmax(scores)]\n",
        "print(\"Recognized word:\", recognized_word)"
      ],
      "metadata": {
        "id": "VRvQH1YLTUtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db25266-e44b-4c81-acb9-e58d61783d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized word: stop\n"
          ]
        }
      ]
    }
  ]
}